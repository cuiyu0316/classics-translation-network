{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path1 = r'uid_relate.xlsx'\n",
    "data1 = pd.read_excel(path1, engine='openpyxl')\n",
    "path2 = r'translations.xlsx'\n",
    "data2 = pd.read_excel(path2, engine='openpyxl')\n",
    "path4 = r'country.xlsx'\n",
    "data4 = pd.read_excel(path4, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e68c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list_v2(input_string):\n",
    "    input_string = input_string.strip(\"[]\")\n",
    "    return [int(num_str) for num_str in input_string.split(\",\")]\n",
    "\n",
    "def filter_1st_element(df):\n",
    "    df_list = df.tolist()\n",
    "    v = None\n",
    "    for item in df_list:\n",
    "        if item == '-':\n",
    "            continue\n",
    "        else:\n",
    "            v = item\n",
    "            break\n",
    "    return v\n",
    "\n",
    "def filter_df_tostring(df):\n",
    "    strrr = []\n",
    "    for i in df.tolist():\n",
    "        strrr.append(i)\n",
    "    return strrr\n",
    "\n",
    "columns1 = data1.columns\n",
    "\n",
    "point_uid = []\n",
    "routids = []\n",
    "directids = []\n",
    "routtype = []\n",
    "routid = 0\n",
    "\n",
    "for index, row in data1.iterrows():\n",
    "    for column in columns1:\n",
    "        if column != \"unique_id\" and row[column] != \"['']\":\n",
    "            str_2_uid = string_to_list_v2(row[column])\n",
    "            for i in str_2_uid:\n",
    "                point_uid.append(row['unique_id'])\n",
    "                routids.append(routid)\n",
    "                directids.append(0)\n",
    "                point_uid.append(i)\n",
    "                routids.append(routid)\n",
    "                directids.append(1)\n",
    "                routtype.append(column)\n",
    "                routtype.append(column)\n",
    "                routid = routid + 1\n",
    "                \n",
    "                \n",
    "point_lon = []\n",
    "point_lat = []\n",
    "point_time = []\n",
    "point_language = []\n",
    "point_country = []\n",
    "point_type = []\n",
    "point_iso = []\n",
    "\n",
    "\n",
    "for j in range(len(point_uid)):\n",
    "    uid1 = point_uid[j]\n",
    "    condition1 = data2['unique_id'] == uid1\n",
    "    filtered_lan_1 = filter_1st_element(data2[condition1]['language'])\n",
    "    filtered_pubtime_1 = filter_1st_element(data2[condition1]['publishyear_1st'])\n",
    "    filtered_publocation_1 = filter_1st_element(data2[condition1]['country'])\n",
    "    filtered_type_1 = filter_1st_element(data2[condition1]['type'])\n",
    "    filtered_lat_1 = filter_1st_element(data2[condition1]['lat'])\n",
    "    filtered_lon_1 = filter_1st_element(data2[condition1]['lon'])\n",
    "    filtered_iso_1 = filter_1st_element(data2[condition1]['country_code_iso2'])\n",
    "  \n",
    "    point_lon.append(filtered_lon_1)\n",
    "    point_lat.append(filtered_lat_1)\n",
    "    point_time.append(filtered_pubtime_1)\n",
    "    point_language.append(filtered_lan_1)\n",
    "    point_country.append(filtered_publocation_1)\n",
    "    point_type.append(filtered_type_1)\n",
    "    point_iso.append(filtered_iso_1)\n",
    "\n",
    "data3 = pd.DataFrame()\n",
    "data3['point_uid'] = point_uid\n",
    "data3['routids'] = routids\n",
    "data3['point_direct'] = directids\n",
    "data3['point_lon'] = point_lon\n",
    "data3['point_lat'] = point_lat\n",
    "data3['point_time'] = point_time\n",
    "data3['point_language'] = point_language\n",
    "data3['point_country'] = point_country\n",
    "data3['point_type'] = point_type\n",
    "data3['point_iso'] = point_iso\n",
    "data3['rout_type'] = routtype\n",
    "\n",
    "point_iso_3 = []\n",
    "point_cn = []\n",
    "for iso in point_iso:\n",
    "    mark = 0\n",
    "    for index, row in data4.iterrows():\n",
    "        if row['iso2'] == iso:\n",
    "            point_iso_3.append(row['iso3'])\n",
    "            point_cn.append(row['cn'])\n",
    "            mark = 1\n",
    "            break\n",
    "    if mark == 0:\n",
    "        point_iso_3.append(\"-\")\n",
    "        point_cn.append(\"-\")\n",
    "        \n",
    "data3['point_iso_3'] = point_iso_3\n",
    "data3['point_cn'] = point_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ab836",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_points = data3[data3['point_direct'] == 0][['routids', 'point_country', 'point_iso', 'point_iso_3', 'point_cn']].rename(columns={'point_country': 'Start Country'})\n",
    "end_points = data3[data3['point_direct'] == 1][['routids', 'point_country', 'point_iso', 'point_iso_3', 'point_cn']].rename(columns={'point_country': 'End Country'})\n",
    "rout_type = data3[data3['point_direct'] == 1][['routids', 'rout_type']]\n",
    "\n",
    "routes = pd.merge(start_points, end_points, on='routids')\n",
    "routes = pd.merge(routes, rout_type, on='routids')\n",
    "\n",
    "route_data = routes.groupby(['Start Country', 'End Country','point_iso_x', 'point_iso_y','point_iso_3_x', 'point_iso_3_y','point_cn_x','point_cn_y','rout_type']).size().reset_index(name='Count')\n",
    "route_data = route_data.pivot_table(index=['Start Country', 'End Country','point_iso_x', 'point_iso_y','point_iso_3_x', 'point_iso_3_y','point_cn_x','point_cn_y'], columns=\"rout_type\", values=\"Count\", aggfunc=\"sum\", fill_value=0).reset_index()\n",
    "route_data[\"Intensity\"] = 1 * route_data[\"retranslation\"] + 0.7 * route_data[\"source text\"]+ 0.3 * route_data[\"reference\"] \n",
    "route_data.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = pd.concat([route_data['point_iso_3_x'], route_data['point_iso_3_y']]).unique()\n",
    "adjacency_matrix_full = pd.DataFrame(index=all_countries, columns=all_countries).fillna(0)\n",
    "for index, row in route_data.iterrows():\n",
    "    if row['point_iso_3_x'] != row['point_iso_3_y']:\n",
    "        adjacency_matrix_full.loc[row['point_iso_3_x'], row['point_iso_3_x']] += row[\"Intensity\"]\n",
    "\n",
    "rows_to_drop = adjacency_matrix_full.index[(adjacency_matrix_full == 0).all(axis=1)]\n",
    "cols_to_drop = adjacency_matrix_full.columns[(adjacency_matrix_full == 0).all(axis=0)]\n",
    "\n",
    "indices_to_drop = rows_to_drop.intersection(cols_to_drop)\n",
    "adjacency_matrix_full = adjacency_matrix_full.drop(index=indices_to_drop, columns=indices_to_drop)\n",
    "\n",
    "csv_file_path = r'adjacency_matrix.csv'\n",
    "adjacency_matrix_full.to_csv(csv_file_path, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:process_data] *",
   "language": "python",
   "name": "conda-env-process_data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
